{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "4iMK5hicZPGZ"
   },
   "source": [
    "# Entrenamiento usando como base un modelo VGG16."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicialización del código."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "VCTK6pNs97EI"
   },
   "source": [
    "Librerías necesarias para trabajar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yP1cOTgh9wIP"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import csv\n",
    "import time\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import multilabel_confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Concatenate, MaxPooling2D, UpSampling2D, Cropping2D, Flatten, Dense, Dropout, GlobalAveragePooling2D, RepeatVector, Reshape\n",
    "from tensorflow.keras.metrics import binary_accuracy, Recall, BinaryCrossentropy\n",
    "from tensorflow.keras.applications import VGG16"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "THRESHOLD = 0.5\n",
    "TEST_SIZE = 0.2\n",
    "VALIDATION_SIZE = 0.25\n",
    "RANDOM_STATE = None\n",
    "NUM_WORKERS = 1\n",
    "USE_MULTIPROCESSING = False\n",
    "WIDTH_IMAGES = 256\n",
    "HEIGHT_IMAGES = 256\n",
    "SAVE_MODEL = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_CSV = 'CXR8'\n",
    "DIR_IMAGES = r'CXR8\\images'\n",
    "DIR_RESULTS = 'Results'\n",
    "CSV_TRAINING = 'Data_Entry_2017_v2020.csv'\n",
    "COLUMN_IMAGE = 'Image Index'\n",
    "COLUMN_LABELS = 'Finding Labels'\n",
    "COLUMN_FEATURE_AGE = 'Patient Age'\n",
    "COLUMN_FEATURE_GENDER = 'Patient Gender'\n",
    "COLUMN_FEATURE_VIEW_POSITION = 'View Position'\n",
    "ADDITIONAL_DATA = [COLUMN_FEATURE_AGE, COLUMN_FEATURE_GENDER, COLUMN_FEATURE_VIEW_POSITION]\n",
    "LABEL_NO_FINDING = 'No Finding'\n",
    "date_test = datetime.now()\n",
    "actual_date = date_test.strftime('%Y-%m-%d.%H-%M-%S')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepara el entorno de colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_GOOGLE_DRIVE = '/content/drive/'\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount(DIR_GOOGLE_DRIVE, force_remount=True)\n",
    "CRX8_DOWNLOAD_FILES = 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asegurate que existen los directorios necesarios para guardar los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(DIR_IMAGES):\n",
    "    os.makedirs(DIR_IMAGES)\n",
    "if not os.path.exists(os.path.join(DIR_RESULTS, 'images')):\n",
    "    os.makedirs(os.path.join(DIR_RESULTS, 'images'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga y preparación de los datos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descarga de los conjuntos de imágenes. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descarga y descomprime los archivos de imágenes desde la web de ChestX-ray14 (https://nihcc.app.box.com/v/ChestXray-NIHCC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%cd /content/\n",
    "links = [\n",
    "    'https://nihcc.box.com/shared/static/vfk49d74nhbxq3nqjg0900w5nvkorp5c.gz',\t# image_01.tar.gz\n",
    "    'https://nihcc.box.com/shared/static/i28rlmbvmfjbl8p2n3ril0pptcmcu9d1.gz',\t# image_02.tar.gz\n",
    "    'https://nihcc.box.com/shared/static/f1t00wrtdk94satdfb9olcolqx20z2jp.gz',\t# image_03.tar.gz\n",
    "    'https://nihcc.box.com/shared/static/0aowwzs5lhjrceb3qp67ahp0rd1l1etg.gz',\t# image_04.tar.gz\n",
    "    'https://nihcc.box.com/shared/static/v5e3goj22zr6h8tzualxfsqlqaygfbsn.gz',\t# image_05.tar.gz\n",
    "    'https://nihcc.box.com/shared/static/asi7ikud9jwnkrnkj99jnpfkjdes7l6l.gz',\t# image_06.tar.gz\n",
    "    'https://nihcc.box.com/shared/static/jn1b4mw4n6lnh74ovmcjb8y48h8xj07n.gz',\t# image_07.tar.gz\n",
    "    'https://nihcc.box.com/shared/static/tvpxmn7qyrgl0w8wfh9kqfjskv6nmm1j.gz',\t# image_08.tar.gz\n",
    "    'https://nihcc.box.com/shared/static/upyy3ml7qdumlgk2rfcvlb9k6gvqq2pj.gz',\t# image_09.tar.gz\n",
    "    'https://nihcc.box.com/shared/static/l6nilvfa9cg3s28tqv1qc1olm3gnz54p.gz',\t# image_10.tar.gz\n",
    "    'https://nihcc.box.com/shared/static/hhq8fkdgvcari67vfhs7ppg2w6ni4jze.gz',\t# image_11.tar.gz\n",
    "    'https://nihcc.box.com/shared/static/ioqwiy20ihqwyr8pf4c24eazhh281pbu.gz'\t# image_12.tar.gz\n",
    "]\n",
    "\n",
    "for n, gz_file_url in enumerate(links):\n",
    "    if n == CRX8_DOWNLOAD_FILES:\n",
    "        break;\n",
    "    gz_file_name = 'images_%02d.tar.gz' % (n + 1)\n",
    "    !wget {gz_file_url} -O {gz_file_name}\n",
    "    !tar -xzf {gz_file_name}\n",
    "    !rm {gz_file_name}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de los datos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga el dataset con las etiquetas y datos de cada radiografía y lo muestra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xrays = pd.read_csv(os.path.join(DIR_CSV, CSV_TRAINING))\n",
    "df_xrays"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtiene las distintas etiquetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Recupera los valores de las clases, pero sin repetirse y ordenados alfabéticamente.\n",
    "labels = list(set(label for labels in df_xrays[COLUMN_LABELS].unique() for label in labels.split('|')))\n",
    "\n",
    "labels = np.sort(labels)\n",
    "\n",
    "#  La etiqueta que representa que no hay enfermedad la vamos a tratar de forma diferente.\n",
    "# En realidad esto sería que no hay ninguna etiqueta de enfermedad. No tendría sentido que\n",
    "# se pudiera dar, por ejemplo, 'no finding|pneumonia'. Por lo tanto hay que eliminarla.\n",
    "# La forma que menos problemas ha dado, es al principio dejarla como una etiqueta más.\n",
    "# Una vez binarizadas las etiquetas, eliminar la columna.\n",
    "labels = np.concatenate(((np.delete(labels, np.where(labels == LABEL_NO_FINDING)[0]), [LABEL_NO_FINDING])))\n",
    "\n",
    "#  Cuenta las clases. Restamos la del 'No finding'.\n",
    "num_labels = len(labels) - 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arreglo de los datos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Código para pruebas, cuando no se trabaja con todo el conjunto de imágenes.\n",
    "\n",
    "Mira los archivos que hay en el directorio de imágenes y selecciona sólo las filas correctas del dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_xrays = os.listdir(DIR_IMAGES)\n",
    "df_xrays = df_xrays[df_xrays[COLUMN_IMAGE].isin(list_xrays)].copy()\n",
    "del list_xrays"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agrega la ruta del directorio de las imágenes al nombre de cada una."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xrays[COLUMN_IMAGE] = df_xrays[COLUMN_IMAGE].apply(lambda i: os.path.join(DIR_IMAGES, i))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binariza las etiquetas en el dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Crear una instancia de MultiLabelBinarizer.\n",
    "mlb = MultiLabelBinarizer(classes=labels)\n",
    "\n",
    "#  Transforma las clases del dataframe.\n",
    "vectors_one_hot_from_labels = list(mlb.fit_transform([txt_labels.split('|') for txt_labels in df_xrays[COLUMN_LABELS]]))\n",
    "\n",
    "#  Elimina la columna correspondiente al 'No finding'.\n",
    "vectors_one_hot_from_labels = np.delete(vectors_one_hot_from_labels, -1, axis=1)\n",
    "\n",
    "#  Elimina ahora la etiqueta del 'No finding' de labels.\n",
    "labels = np.delete(labels, np.where(labels == LABEL_NO_FINDING)[0])\n",
    "\n",
    "#  Actualiza el dataframe.\n",
    "df_xrays[COLUMN_LABELS] = list(vectors_one_hot_from_labels)\n",
    "\n",
    "del vectors_one_hot_from_labels\n",
    "del mlb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codifica los datos adicionales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Codificamos la columna de género, M por 0 y V por 1.\n",
    "df_xrays[COLUMN_FEATURE_GENDER] = df_xrays[COLUMN_FEATURE_GENDER].map({'M': 0, 'F': 1})\n",
    "\n",
    "#  Normalizamos la edad. Supondremos que las edades posibles estén comprendidas entre 0 \n",
    "# y 100.\n",
    "df_xrays[COLUMN_FEATURE_AGE] /= 100.\n",
    "\n",
    "#  Codificamos la columna con la posición de la imagen, PA (Posteroanterior) por 0 y \n",
    "# AP (anteroposterior) por 1.\n",
    "df_xrays[COLUMN_FEATURE_VIEW_POSITION] = df_xrays[COLUMN_FEATURE_VIEW_POSITION].map({'PA': 0, 'AP': 1})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muestra el conjunto resultante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xrays"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcula los pesos de cada etiqueta para reforzar el aprendizaje de casos positivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Obten las proporciones de muestras positivas por etiqueta.\n",
    "positives_ratio = np.sum(df_xrays[COLUMN_LABELS].to_list(), axis=0) / len(df_xrays)\n",
    "\n",
    "# Crea el diccionario de pesos.\n",
    "label_weights = {label: 1/ratio for label, ratio in enumerate(positives_ratio)}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ECbJDu_j-PFd"
   },
   "source": [
    "Prepara los conjuntos de entrenamiento, validación y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Divide todo el conjunto en entrenamiento y prueba.\n",
    "df_xrays_train, df_xrays_test = train_test_split(df_xrays, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
    "del df_xrays\n",
    "\n",
    "# Divide el conjunto de entrenamiento recien creado en entrenamiento y validación.\n",
    "df_xrays_train, df_xrays_val = train_test_split(df_xrays_train, test_size=TEST_SIZE, random_state=RANDOM_STATE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crea la red utilizando el modelo preentrenado VGG16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Parte densa para los datos adicionales.\n",
    "def dense_branch(inputs):\n",
    "    fully_conn = Dense(64, activation=tf.nn.relu, name='additional_info_dense_1')(inputs)\n",
    "    fully_conn = Dense(32, activation=tf.nn.relu, name='additional_info_dense_2')(fully_conn)\n",
    "    \n",
    "    return fully_conn\n",
    "\n",
    "#  Carga el modelo VGG16 preentrenado sin las capas densas incluidas.\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(WIDTH_IMAGES, HEIGHT_IMAGES, 3))\n",
    "\n",
    "#  Marca las capas del modelo preentrenado como no entrenables.\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "#  Agregar capas densas adicionales\n",
    "pretrain_model = base_model.output\n",
    "pretrain_model = GlobalAveragePooling2D()(pretrain_model)\n",
    "\n",
    "\n",
    "#  La entrada serán los datos adicionales de la imagen, por lo tanto se corresponde con el ancho y el alto. Al ser\n",
    "# en blanco y negro sólo es necesario un canal.\n",
    "inputs_dense_block = Input(shape=(len(ADDITIONAL_DATA),), name='additional_info')\n",
    "dense_block = dense_branch(inputs_dense_block)\n",
    "\n",
    "#  Fusiona cada rama\n",
    "fusion_layer = Concatenate()([pretrain_model, dense_block])\n",
    "\n",
    "#  Pademos el resultado a las capas densas.\n",
    "fully_conn = Dense(128, activation=tf.nn.relu, name='dense_1')(fusion_layer)\n",
    "fully_conn = Dense(64, activation=tf.nn.relu, name='dense_2')(fully_conn)\n",
    "fully_conn = Dense(32, activation=tf.nn.relu, name='dense_3')(fully_conn)\n",
    "outputs = Dense(num_labels, activation=tf.nn.sigmoid, name='outputs')(fully_conn)\n",
    "\n",
    "model = Model(inputs=[base_model.input, inputs_dense_block], outputs=outputs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compila el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[binary_accuracy]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muestra el diagrama del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, to_file=os.path.join(DIR_RESULTS, 'images', 'model-{}.png'.format(actual_date)), show_shapes=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muestra el resumen de la arquitectura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_report = model.summary()\n",
    "summary_report"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generador personalizado de datos, para ir cargando los datos por lotes al entrenar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, df, batch_size, img_width, img_height, labels, shuffle=True):\n",
    "        self.df = df.copy()\n",
    "        self.batch_size = batch_size\n",
    "        self.img_width = img_width\n",
    "        self.img_height = img_height\n",
    "        self.additional_info_cols = [COLUMN_FEATURE_AGE, COLUMN_FEATURE_GENDER]\n",
    "        self.labels = labels\n",
    "        self.num_classes = len(labels)\n",
    "        self.shuffle = shuffle\n",
    "        if shuffle:\n",
    "            self.on_epoch_end()\n",
    "        \n",
    "    def __len__(self):\n",
    "        # Número de lotes que devolverá este generador.\n",
    "        return int(np.ceil(len(self.df) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        #  Devuelve un lote.\n",
    "        #  Selecciona las filas del dataframe correspondientes al lote index.\n",
    "        batch_df = self.df[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        X, y = self.__data_generation(batch_df)\n",
    "        return X, y\n",
    "    \n",
    "    def __data_generation(self, batch_df):\n",
    "        batch_images = []\n",
    "        batch_labels = []\n",
    "        batch_additional_info = []\n",
    "\n",
    "        for i, row in batch_df.iterrows():\n",
    "            path_img = row[COLUMN_IMAGE]\n",
    "            tensor_img = tf.io.read_file(path_img)\n",
    "            tensor_img = tf.image.decode_png(tensor_img)\n",
    "            \n",
    "            #  Redimensiona la imagen.\n",
    "            tensor_img = tf.image.resize(tensor_img, [self.img_width, self.img_height])\n",
    "\n",
    "            #  Algunas imágenes tienen 4 canales. Hay que pasarles a grises.\n",
    "            if tf.shape(tensor_img)[2] > 1:\n",
    "                #  Elimina el canal alpha.\n",
    "                tensor_img = tf.slice(tensor_img, [0, 0, 0], [self.img_width, self.img_height, 3])\n",
    "\n",
    "                #  Pasa a escala de grises.\n",
    "                tensor_img = tf.image.rgb_to_grayscale(tensor_img)\n",
    "\n",
    "            #  Normaliza los valores de los píxeles a un rango de [-1, 1].\n",
    "            tensor_img = (tf.cast(tensor_img, tf.float32) - 127.5) / 127.5\n",
    "\n",
    "            #  Aquí estamos trabajando con un modelo preentrenado que requiere una entrada\n",
    "            # de 3 canales.\n",
    "            tensor_img = np.concatenate((tensor_img, tensor_img, tensor_img), axis=2)\n",
    "\n",
    "            batch_images.append(img_to_array(tensor_img))\n",
    "            \n",
    "            #  Agregra las variables con la información adicional.\n",
    "            additional_info = row[ADDITIONAL_DATA].values.astype(np.float32)\n",
    "            batch_additional_info.append(additional_info)\n",
    "            \n",
    "            #  Agrega las etiquetas de cada radiografía.\n",
    "            batch_labels.append(row[COLUMN_LABELS])\n",
    "        \n",
    "        X = [\n",
    "             np.array(batch_images),\n",
    "             np.asarray(batch_additional_info).astype('float32')\n",
    "        ]\n",
    "        y = np.array(batch_labels)\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.df = self.df.sample(frac=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrena y evalua el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = CustomDataGenerator(df_xrays_train, batch_size=BATCH_SIZE,\n",
    "                                      img_width=WIDTH_IMAGES, img_height=HEIGHT_IMAGES, \n",
    "                                      labels=labels, shuffle=True\n",
    ")\n",
    "\n",
    "validation_generator = CustomDataGenerator(df_xrays_val, batch_size=BATCH_SIZE,\n",
    "                                      img_width=WIDTH_IMAGES, img_height=HEIGHT_IMAGES, \n",
    "                                      labels=labels, shuffle=True\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "history = model.fit(train_generator, \n",
    "                    epochs=NUM_EPOCHS,\n",
    "                    validation_data=validation_generator,\n",
    "                    steps_per_epoch=math.ceil(df_xrays_train.shape[0] / BATCH_SIZE),\n",
    "                    shuffle=True,\n",
    "                    workers=NUM_WORKERS,\n",
    "                    use_multiprocessing=USE_MULTIPROCESSING,\n",
    "                    class_weight=label_weights\n",
    ")\n",
    "training_time = time.time() - start_time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muestra las gráficas de perdida y precisión binaria por ciclo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea la figura y las subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2,  figsize=(15, 5))\n",
    "\n",
    "# Gráfica de perdida por ciclo.\n",
    "ax1.set_title('Loss / Epoch')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.plot(history.history['loss'])\n",
    "\n",
    "# Gráfica de precisión binaria por ciclo.\n",
    "ax2.set_title('Binary Accuracy / Epoch')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Binary Accuracy')\n",
    "ax2.plot(history.history['binary_accuracy'])\n",
    "\n",
    "plt.savefig(os.path.join(DIR_RESULTS, 'images', 'loss-binary-accuracy-{}.png'.format(actual_date)), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realiza la evaluación del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = CustomDataGenerator(df_xrays_test, batch_size=BATCH_SIZE,\n",
    "                                      img_width=WIDTH_IMAGES, img_height=HEIGHT_IMAGES, \n",
    "                                      labels=labels, shuffle=False\n",
    ")\n",
    "labels_predictions_scores = model.predict(test_generator)\n",
    "\n",
    "#  Pon a 1 aquellas que sean mayores o iguales al umbral y 0 al resto.\n",
    "labels_predictions = np.where(labels_predictions_scores > THRESHOLD, 1, 0)\n",
    "\n",
    "#  Prepara también un array con las etiquetas auténticas de cada caso de test.\n",
    "labels_test = np.concatenate(df_xrays_test[COLUMN_LABELS].to_numpy()).reshape(labels_predictions.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guarda los resultados en csv, por si hay que revisarlos a mano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DIR_RESULTS, 'Tests.{}.csv'.format(actual_date)), 'w', newline='') as f:\n",
    "    writer = csv.writer(f, delimiter='\\t')\n",
    "    for row in labels_test:\n",
    "        writer.writerow(row)\n",
    "\n",
    "with open(os.path.join(DIR_RESULTS, 'Predictions.{}.csv'.format(actual_date)), 'w', newline='') as f:\n",
    "    writer = csv.writer(f, delimiter='\\t')\n",
    "    for row in labels_predictions:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matriz de confusión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_confusion_matrix = multilabel_confusion_matrix(labels_test, labels_predictions)\n",
    "print(ml_confusion_matrix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Métricas del módelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_report = classification_report(labels_test, labels_predictions, target_names=labels, zero_division=0)\n",
    "print(cl_report)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curva ROC de cada etiqueta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr = dict()\n",
    "tpr = dict()\n",
    "thresholds = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(len(labels)):\n",
    "    fpr[i], tpr[i], thresholds[i] = roc_curve(labels_test[:, i], labels_predictions_scores[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "fpr_macro, tpr_macro, _ = roc_curve(labels_test.ravel(), labels_predictions_scores.ravel())\n",
    "roc_auc_macro = auc(fpr_macro, tpr_macro)\n",
    "\n",
    "# Dibujar gráficas ROC\n",
    "cols = 4\n",
    "rows = math.ceil((len(labels) + 1) / cols)\n",
    "fig, ax = plt.subplots(rows, cols, figsize=(cols * 4, rows * 4))\n",
    "for i, label in enumerate(labels):\n",
    "    row = i // cols\n",
    "    col = i % cols\n",
    "    ax[row][col].plot([0, 1], [0, 1], linestyle='--', lw=2, color='red', alpha=0.8)\n",
    "    ax[row][col].plot(fpr[i], tpr[i], color='blue', lw=2, alpha=0.8) \n",
    "    ax[row][col].set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05], title='Curva ROC {0} (AUC = {1:0.2f})'.format(labels[i], roc_auc[i]))\n",
    "i = i + 1\n",
    "row = i // cols\n",
    "col = i % cols\n",
    "ax[row][col].plot([0, 1], [0, 1], linestyle='--', lw=2, color='red', alpha=0.8)\n",
    "ax[row][col].plot(fpr_macro, tpr_macro, color='blue', lw=2, alpha=0.8)\n",
    "ax[row][col].set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05], title='Curva ROC macro promediada (AUC = {0:0.2f})'.format(roc_auc_macro))\n",
    "for i in range(col + 1, cols):\n",
    "    ax[row][i].axis('off')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(os.path.join(DIR_RESULTS, 'images', 'roc-curves-{}.png'.format(actual_date)), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representa visualmente imágenes que ha clasificado bien y mal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = 40\n",
    "num_cols = 3\n",
    "\n",
    "# matplotlib.use('ps')\n",
    "# rc('text', usetex = True)\n",
    "# rc('text.latex', preamble = 'usepackage{color}')\n",
    "fig, ax = plt.subplots(nrows=num_rows, ncols=num_cols, figsize=(6 * num_cols, 3 * num_rows), dpi=128, facecolor='none')\n",
    "plt.subplots_adjust(wspace=2.5, hspace=0.01)\n",
    "\n",
    "def draw_images():\n",
    "    test = row = col = 0\n",
    "    for i in range(len(test_generator)):\n",
    "        X_test, y_test = test_generator[i]\n",
    "        X_test = X_test[0]\n",
    "        for X, y in zip(X_test, y_test):\n",
    "            list_labels_true = []\n",
    "            list_labels_pred = []\n",
    "\n",
    "            #  Comprueba que enfermedades tienen en común el test y la predicción.\n",
    "            for n, label in enumerate(labels):\n",
    "                if y[n] == labels_predictions[test][n] and y[n] == 1:\n",
    "                    #  La radiografía del test tenía esta enfermedad y se ha clasificado bien.            \n",
    "                    list_labels_true.append(label)\n",
    "                    list_labels_pred.append(label + ' [' +\n",
    "                                    '{:.2f}'.format(labels_predictions_scores[test][n] * 100.) +\n",
    "                                    '%]')\n",
    "                elif y[n] != labels_predictions[test][n] and y[n] == 1:\n",
    "                    #  La radiografía del test tenía esta enfermedad, pero no se ha clasificado bien.\n",
    "                    list_labels_true.append(label)\n",
    "                elif y[n] != labels_predictions[test][n] and y[n] == 0:\n",
    "                    #  La radiografía del test no tenía esta enfermedad, y se ha clasificado mal.\n",
    "                    list_labels_pred.append(label + ' [' +\n",
    "                                    '{:.2f}'.format(labels_predictions_scores[test][n] * 100.) +\n",
    "                                    '%]')\n",
    "                    \n",
    "            #  Comprueba los casos del 'No Finding' y los colores de los marcos.\n",
    "            if len(list_labels_true) == 0 and len(list_labels_pred) == 0:\n",
    "                #  Si la radiografía del test no tenía ninguna enfermedad y no se ha clasificado\n",
    "                # ninguna, pon ambos textos en verde. Pon el marco de la imagen en verde también.\n",
    "                text_labels_true = LABEL_NO_FINDING\n",
    "                text_labels_pred = LABEL_NO_FINDING\n",
    "                box_img_color = 'green'\n",
    "            elif len(list_labels_true) == 0:\n",
    "                #  Si la radiografía no tenía ninguna enferemedad, pero se ha clasificado alguna,\n",
    "                # pon el texto en rojo (la predicción ha sido totalmente incorrecta).\n",
    "                text_labels_true = LABEL_NO_FINDING\n",
    "                box_img_color = 'red'\n",
    "            elif len(list_labels_pred) == 0:\n",
    "                #  Si no se ha clasificado ninguna enfermedad pero la radiografía tenía alguna,\n",
    "                # pon el texto de la predicción y el marco de la imagen en rojo.\n",
    "                text_labels_pred = LABEL_NO_FINDING\n",
    "                box_img_color = 'red'\n",
    "            else:\n",
    "                #  La radiografía tiene alguna enfermedad y se han clasificado también algunas.\n",
    "                if np.array_equal(y, labels_predictions[test]):\n",
    "                    #  Los vectores son iguales, eso es que la clasificación ha sido perfecta.\n",
    "                    # Ponemos el marco en verde\n",
    "                    box_img_color = 'green'\n",
    "                elif np.count_nonzero(y & labels_predictions[test]) > 0:\n",
    "                    #  Hay alguna enfermedad que se ha clasificado bien. Ponemos el marco en \n",
    "                    # amarillo\n",
    "                    box_img_color = 'yellow'\n",
    "                else:\n",
    "                    #  No ha clasificado bien ninguna enferemedad. Ponemos el marco en rojo.\n",
    "                    box_img_color = 'red'\n",
    "\n",
    "            #  Formamos los textos en los casos que correspondan.\n",
    "            if len(list_labels_true) > 0:\n",
    "                text_labels_true = ', '.join(list_labels_true)\n",
    "\n",
    "            if len(list_labels_pred) > 0:\n",
    "                text_labels_pred = ', '.join(list_labels_pred)\n",
    "\n",
    "            #  Quita los ejes y la rejilla.\n",
    "            ax[row][col].axis('off')\n",
    "            ax[row][col].grid(False)\n",
    "            ax[row][col].set_xticks([])\n",
    "            ax[row][col].set_yticks([])\n",
    "            ax[row][col].set_xticklabels([])\n",
    "            ax[row][col].set_yticklabels([])\n",
    "\n",
    "            #  Dibuja la imagen.\n",
    "            ax[row][col].imshow(((X * 127) + 128).astype(np.uint8), extent=[0, 128, 0, 128], cmap='gray')\n",
    "            \n",
    "            #  Agrega el marco de borde 5\n",
    "            ax[row][col].add_artist(plt.Rectangle((0, 0),\n",
    "                            WIDTH_IMAGES - 1, HEIGHT_IMAGES - 1,\n",
    "                            fill=False,\n",
    "                            edgecolor=box_img_color,\n",
    "                            lw = 10)\n",
    "            )\n",
    "        \n",
    "            #  Pon las enfermedades verdaderas.\n",
    "            ax[row][col].text(0, -0.1,\n",
    "                              f'True: {text_labels_true}',\n",
    "                              fontsize=14,\n",
    "                              color=box_img_color,\n",
    "                              ha='left',\n",
    "                              transform=ax[row][col].transAxes\n",
    "            )\n",
    "\n",
    "            #  Pon las enfermedades clasificadas.\n",
    "            ax[row][col].text(0, -0.2,\n",
    "                              f'Pred: {text_labels_pred}',\n",
    "                              fontsize=14,\n",
    "                              color=box_img_color,\n",
    "                              ha='left',\n",
    "                              transform=ax[row][col].transAxes\n",
    "            )\n",
    "\n",
    "            test = test + 1\n",
    "            col = col + 1\n",
    "            if col == num_cols:\n",
    "                row = row + 1\n",
    "                if row == num_rows:\n",
    "                    return\n",
    "                col = 0\n",
    "draw_images()\n",
    "plt.savefig(os.path.join(DIR_RESULTS, 'images', 'tests-{}.png'.format(actual_date)), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardemos los datos del entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_file = 'Resultados - {}.md'.format(actual_date)\n",
    "\n",
    "with open(os.path.join(DIR_RESULTS, report_file), 'w') as f:\n",
    "    print('# Resumen de la prueba con fecha {}\\n'.format(date_test.strftime('%d/%m/%Y %H:%M:%S')), file=f)\n",
    "\n",
    "    #  Escribe el tiempo que tardo en realizar el entrenamiento.\n",
    "    print('Tiempo de entrenamiento del modelo: {}\\n.'.format(time.strftime('%H horas %M minutos %S segundos', time.gmtime(training_time))), file=f)\n",
    "\n",
    "    #  Escribe el resumen de la arquitectura del modelo.\n",
    "    print('## Arquitectura del modelo.\\n\\n```', file=f)\n",
    "    model.summary(print_fn = lambda sum: print(sum + '\\n', file=f))\n",
    "    print('```\\n', file=f)\n",
    "\n",
    "    #  Pon el diagrama de la arquitectura.\n",
    "    print('![Arquitectura de la red](images/model-{}.png)\\n'.format(actual_date), file=f)\n",
    "\n",
    "    #  Pon las gráficas de pérdida y precisión binaria.\n",
    "    print('## Pérdida y precisión binaria.\\n', file=f)\n",
    "    print('![Pérdida y precisión binaria](images/loss-binary-accuracy-{}.png)\\n'.format(actual_date), file=f)\n",
    "\n",
    "    #  Pon la matriz de confusión.\n",
    "    print('## Matriz de confusión.\\n', file=f)\n",
    "    for mat, label in zip(ml_confusion_matrix, labels):\n",
    "        print('* ' + label + '\\n```python', file=f)\n",
    "        print(mat, file=f)\n",
    "        print('```\\n', file=f)\n",
    "\n",
    "    #  Escribe el informe con los resultados de la clasificación.\n",
    "    print('## Resultados de la clasificación.\\n\\n```', file=f)\n",
    "    print(cl_report, file=f)\n",
    "    print('```\\n', file=f)\n",
    "\n",
    "    #  Pon las gráficas de las curvas ROC.\n",
    "    print('## Curvas ROC de cada etiqueta.\\n', file=f)\n",
    "    print('![Curvas ROC de cada etiqueta](images/ROC-curves-{}.png)\\n'.format(actual_date), file=f)\n",
    "\n",
    "\n",
    "    #  Pon imágenes de las radiografías con los tests.\n",
    "    print('## Ejemplos de las predicciones del modelo.\\n\\n', file=f)\n",
    "    print('    Verde: Clasificación correcta\\n', file=f)\n",
    "    print('    Amarillo: Clasificación parcial\\n', file=f)\n",
    "    print('    Rojo: Clasificación incorrecta\\n', file=f)\n",
    "    print('![Tests](images/tests-{}.png)\\n'.format(actual_date), file=f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos el modelo creado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE_MODEL:\n",
    "    model.save(os.path.join(DIR_RESULTS, 'Model-Base-VGG16-Local.{}.h5'.format(actual_date)))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
